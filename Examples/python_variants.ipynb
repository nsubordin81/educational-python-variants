{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c18e86",
   "metadata": {},
   "source": [
    "## Setting The Stage With A Pretend Scenario\n",
    "\n",
    "For demoing I wanted to find an example of something non-trivial to simulate an actual coding situation where writing straight CPython is insufficient performance wise and you have to start looking for solutions with Python alternatives.\n",
    " \n",
    "Scenario: Your favorite band, 2 Pegasus Tasks, just released a new single. However, in their usual style, they did it with a twist.\n",
    "\n",
    "Instead of distributing the song on Spotify or some other distribution platform, for its initial release they segmented  the audio file binary into tiny substrings and then inserted them according to a     secret pattern into a bunch of longer strings to create an internet scavenger hunt. \n",
    "\n",
    "Any group that is able to piece the song together gets a cash prize on the condition that they don't share it or how t    hey got it with others. They have provided a preliminary list of 300 strings, 100 of which the've confirmed do contain a chunk of the song, and 200 of which don't.\n",
    "\n",
    "You and a group of friends have managed to scrape down all known instances of these string sequences and tried some linear but you can't make heads or tails of what they mean. When you analyze the seque    nces by hand, sometimes you think you've found a pattern but then another example breaks it. It definitely looks like the function for the pattern will be non-linear in nature.\n",
    "\n",
    "So you have the idea to use a Support Vector Machine based on a string kernel to learn a boundary between what is part of the pattern and what is not in higher dimensional space. You find a whitepaper about string subsequence kernels that looks like just what you need. You search through libraries online like Scikit Learn and NLTK but in this imaginary scenario, you can't find a decent implemntation of this kernel function anywhere, so you'll have to write your own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99441efa",
   "metadata": {},
   "source": [
    "### Example 1: Just CPython\n",
    "\n",
    "After pouring over the whitepaper and mayber some supplemental material to make sure you understand the concepts, you are able to create an implementation of the string-subsequence-kernel. You are ready to run it, let's simulate that by going to an older revision of our example code which is just written in CPython with some profiling lines to show us how fast it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6a8da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "[[0.8451728  0.78146246 0.88319993 0.86031583]\n",
      " [0.99737074 0.72270543 0.86173297 0.86350414]\n",
      " [0.78265891 0.66158364 0.83420016 0.80619043]\n",
      " [0.74976104 0.61763655 0.71480048 0.69580217]]\n",
      "Running String Kernel on the strings took: 17.162577100039925 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "\"\"\"\n",
    "this code is derivative of https://github.com/helq/python-ssk/commit/6acee597ff37f7e7e12dd8651421a4d34c5dad70\n",
    "by https://github.com/helq,  which is licensed under Creattive Commons Zero v1.0 Universal / \n",
    "changes: removing lodhi assertions because we know it works, changing script handling into function, \n",
    "adding profiling code, changing inputs to exagerrate performance problem. \n",
    "Do check that repo out if you actually want to learn about ssk/get a fast implementation for practical purposes.)\n",
    "\"\"\"\n",
    "# Kernel defined by Lodhi et al. (2002)\n",
    "def ssk(s, t, n, lbda, accum=False):\n",
    "    dynamic = {}\n",
    "\n",
    "    def k_prim(s, t, i):\n",
    "        # print( \"k_prim({},{},{})\".format(s, t, i) )\n",
    "        if i == 0:\n",
    "            # print( \"k_prim({},{},{}) => 1\".format(s, t, i)  )\n",
    "            return 1.\n",
    "        if min(len(s), len(t)) < i:\n",
    "            # print( \"k_prim({},{},{}) => 0\".format(s, t, i)  )\n",
    "            return 0.\n",
    "        if (s,t,i) in dynamic:\n",
    "            return dynamic[(s,t,i)]\n",
    "\n",
    "        x = s[-1]\n",
    "        s_ = s[:-1]\n",
    "        indices = [i for i, e in enumerate(t) if e == x]\n",
    "        toret = lbda * k_prim(s_, t, i) \\\n",
    "              + sum( k_prim(s_, t[:j], i-1) * (lbda**(len(t)-j+1)) for j in indices )\n",
    "        # print( \"k_prim({},{},{}) => {}\".format(s, t, i, toret) )\n",
    "        dynamic[(s,t,i)] = toret\n",
    "        return toret\n",
    "\n",
    "    def k(s, t, n):\n",
    "        # print( \"k({},{},{})\".format(s, t, n) )\n",
    "        if n <= 0:\n",
    "            raise \"Error, n must be bigger than zero\"\n",
    "        if min(len(s), len(t)) < n:\n",
    "            # print( \"k({},{},{}) => 0\".format(s, t, n) )\n",
    "            return 0.\n",
    "        x = s[-1]\n",
    "        s_ = s[:-1]\n",
    "        indices = [i for i, e in enumerate(t) if e == x]\n",
    "        toret = k(s_, t, n) \\\n",
    "              + lbda**2 * sum( k_prim(s_, t[:j], n-1) for j in indices )\n",
    "        # print( \"k({},{},{}) => {}\".format(s, t, n, toret) )\n",
    "        return toret\n",
    "\n",
    "    if accum:\n",
    "        toret = sum( k(s, t, i) for i in range(1, min(n,len(s),len(t))+1) )\n",
    "    else:\n",
    "        toret = k(s, t, n)\n",
    "\n",
    "    # print( len(dynamic) )\n",
    "    return toret\n",
    "\n",
    "def string_kernel(xs, ys, n, lbda):\n",
    "    if len(xs.shape) != 2 or len(ys.shape) != 2 or xs.shape[1] != 1 or ys.shape[1] != 1:\n",
    "        raise \"The shape of the features is wrong, it must be (n,1)\"\n",
    "\n",
    "    lenxs, lenys = xs.shape[0], ys.shape[0]\n",
    "\n",
    "    mat = np.zeros( (lenxs, lenys) )\n",
    "    for i in range(lenxs):\n",
    "        for j in range(lenys):\n",
    "            mat[i,j] = ssk(xs[i,0], ys[j,0], n, lbda, accum=True)\n",
    "\n",
    "    mat_xs = np.zeros( (lenxs, 1) )\n",
    "    mat_ys = np.zeros( (lenys, 1) )\n",
    "\n",
    "    for i in range(lenxs):\n",
    "        mat_xs[i] = ssk(xs[i,0], xs[i,0], n, lbda, accum=True)\n",
    "    for j in range(lenys):\n",
    "        mat_ys[j] = ssk(ys[j,0], ys[j,0], n, lbda, accum=True)\n",
    "\n",
    "    return np.divide(mat, np.sqrt(mat_ys.T * mat_xs))\n",
    "\n",
    "def evaluate_ssk():\n",
    "    print(\"Testing...\")\n",
    "    \n",
    "    ## code for the pretend scenario, long binary sequences\n",
    "    s1 = np.array([\"101110010010111110101011100000101000010010111100101011010011011010110111\", \\\n",
    "                   \"101000010010111111111111110000010100001001011110010101101001101101011011\", \\\n",
    "                   \"101000010010111110101011100011111111101001011110010101101001101101011011\", \\\n",
    "                   \"10111111001011111010101110000010100001001011110010101101001101101011011\"]).reshape((4,1))\n",
    "    s2 = np.array([\"10100001001011111111111110000010100001001011110010101101001101101011011\", \\\n",
    "                   \"10100001001011111010101110000010100001001011110010111111111101101011011\", \\\n",
    "                   \"10100001001011111010101110000010100011101011110010101101001101101011011\", \\\n",
    "                   \"10100001001011111010101110110010100001001011110010101101001111111011011\"]).reshape((4, 1))\n",
    "\n",
    "    # code for pretend scenario, we are looking for common substrings up to 8 chars in length, because that could be a byte\n",
    "    print( string_kernel(s1, s2, 11, 1.) )\n",
    "    \n",
    "print(f\"Running String Kernel on the strings took: \\\n",
    "{timeit.timeit('evaluate_ssk()', setup='from __main__ import evaluate_ssk', number=1)} seconds\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aca40f",
   "metadata": {},
   "source": [
    "### CPython Is Too Slow. . . \n",
    "\n",
    "Oh, no! Don't know what it shows on your machine but mine had ~16 seconds and that is no bueno. The real strings were much longer than that, and the SVM is goingo to need to pairwise compare thousands of them at maybe even longer subsequence values. If you want to be able to iterate and tune your SVM model quickly, we need to build a better mousetrap.\n",
    "\n",
    "What have we got? Well, Pypy is supposed to be a faster drop in replacement for CPython right? And even though we know it won't help us with the already optimized numpy operations, looks like a lot of the bottleneck is good old fashioned python for loops. Pypy should be able to figure out how to compile those down to machine code for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d86bf",
   "metadata": {},
   "source": [
    "## Example 2 Pypy To The Rescue?\n",
    "\n",
    "So For This Example, we are going to run the same code, but swap out our Python 3 kernel in jupyter for a Pypy one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
